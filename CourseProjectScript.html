<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Coursera Machine Learning - Course Project</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>Coursera Machine Learning - Course Project</h2>

<p>#set the working directory to where the data files are located</p>

<p>setwd(&quot;C:/Users/Esherida/Documents/R/Coursera/MachineLearning&quot;)</p>

<p>#call on the libraries that will be needed</p>

<p>library(caret)</p>

<p>library(ggplot2)
library(randomForest)</p>

<p>#Next, read the training and testing data from the files already downloaded from
#the website</p>

<p>training &lt;- read.csv(&quot;pml-training.csv&quot;, na.strings=c(&quot;NA&quot;,&quot;#DIV/0!&quot;,&quot;&quot;))
testing &lt;- read.csv(&quot;pml-testing.csv&quot;, na.strings=c(&quot;NA&quot;,&quot;#DIV/0!&quot;,&quot;&quot;))</p>

<p>#Take a look at the data provided (training only!) so we know more about how to build our model.
#The goal of the model is to use any variables provided to predict the manner
#in which a person did the exercise (classe variable tells us this- classes A through E).</p>

<p>names(training)
str(training)
summary(training)
summary(training$classe) # this is the variable/outcome we want to predict from the model</p>

<p>#Before doing anything else, we will set aside a subset of our training data for
#cross-validation (40% for cross-validation, 60% to train on).
#Remember, we are going to predict the variable &quot;classe&quot; using the other variables to predict</p>

<p>inTrain &lt;- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTrain &lt;- training[inTrain, ]
myTest &lt;- training[-inTrain, ]</p>

<p>#to see the dimensions of our training subset (which we will train on)</p>

<p>dim(myTrain)</p>

<p>#to see the dimensions of our testing subset (which we will cross-validate on)</p>

<p>dim(myTest)</p>

<p>#to create a scatter plot matrix to view the data:</p>

<p>featurePlot(x=training[, 150:159], y = training$classe, plot = &#39;pairs&#39;)</p>

<p>#we know from looking at the data that there are some variables that will not be useful
#to us. There are some variables that are mainly missing (NA), as well as some variables
#that do not have any relation to the outcome variable, for example, the 1st column (x),
#which is just an index of the row number. There also may be variables with very little
#variance, which would also not be useful to us.</p>

<p>#first, let&#39;s remove the variables that are mostly missing
#we will make our threshold greater than 60%:</p>

<p>mytrain_subset &lt;- myTrain</p>

<p>#make a new dataframe that we will edit and remove columns from,
#so the original still exists</p>

<p>for (i in 1:length(myTrain)) {
  if (sum(is.na(myTrain[ , i])) / nrow(myTrain) &gt; .60) {
    for (j in 1:length(mytrain_subset)) {
      if (length(grep(names(myTrain[i]), names(mytrain_subset)[j]))==1) {
        mytrain_subset &lt;- mytrain_subset[ , -j]
      }
    }
  }
}</p>

<p>#to see the dimensions of our subset - and how many columns/variales we removed
#we removed 100 variables (160 - 60 = 100)
dim(mytrain_subset)</p>

<p>#to see which variables are left:
names(mytrain_subset)</p>

<p>#next, let&#39;s get rid of the variables that are obviously not predictors 
#like the time of day they were performing the exercise, and their name. While time of day
#might help predict the correctness/incorrectness of an exercise in a different study (
#for example, if more fatigued people perform the exercise worse), this study had persons
#purposely performing the exercised incorrectly so the machines could measure their body -
#the the persons name, the time of day, and the window is irrelevant here.
#these are the first 7 variables, so we will keep the rest:
mytrain_subset2 &lt;- mytrain_subset[,8:length(mytrain_subset)]</p>

<p>#Next, we will remove all variables with near zero variance
NearZeroV &lt;- nearZeroVar(mytrain_subset2, saveMetrics = TRUE)
NearZeroV # they are all false, so there are none to remove</p>

<p>#Looks like &#39;mytrain_subset2&#39; is the final dataset to do our model training on:
dim(mytrain_subset2)
names(mytrain_subset2)
#we have 52 variables to use to predict the one variable, &#39;classe&#39;</p>

<p>#Time to build the model
#We will use Random Forest as our machine learning alghorithem because, as one of the class
#lectures mentioned, &quot;it&#39;s one of the most widely used and highly accurate methods
#for prediction&quot;
#also because I am have a problem installing &quot;rattle&quot; (doesn&#39;t exist for R version 3.4.2?)
#and therefore cannot do a fancyRpartPlot
#and some of the other commands from the rattle library</p>

<p>#from lecture:</p>

<p>modFit &lt;- train(classe~., data=mytrain_subset2, method=&quot;rf&quot;, prox=TRUE)</p>

<p>#this makes a bunch of different trees
#can look at specific trees in the model with:
#getTree(modFit$finalModel, k=2)
#this gives me the second tree (k=2)</p>

<p>#Let&#39;s try the &#39;randomForest&#39; function instead</p>

<p>set.seed(291989)</p>

<p>#so the results can be reproduced by me and others</p>

<p>modFit &lt;- randomForest(classe ~ ., data = mytrain_subset2)
modFit</p>

<p>#cross validation on the testing data (40% subset of original training set, put aside
#for cross-validation)
#the accuracy here will also tell me my expected out of sample error</p>

<p>predict1 &lt;- predict(modFit, myTest, type = &quot;class&quot;)
confusionMatrix(myTest$classe, predict1)</p>

<p>#accuracy is 99.35%, so that can be expected to be inform my out-of-sample error
#(100-99.35 = 0.65%), considering
#my cross-validation set is essentially &quot;out of sample&quot; because it wasn&#39;t used for any
#of the training</p>

<p>#just out of curiosity, what was my in sample erro?
#in sample error would be gleaned from the accuracy of the training set, which was used to
#train the model - we would expect this to be slightly over-fit, and for the out of sample
#error to be greater because the model was training on this exact data</p>

<p>predict_train &lt;- predict(modFit, myTrain, type = &quot;class&quot;)
confusionMatrix(myTrain$classe, predict_train)</p>

<p>#another way to do the same thing - not using &quot;randomForest&quot;:</p>

<p>modFit2 &lt;- train(classe ~., method = &quot;rf&quot;, trControl=trainControl(method = &quot;cv&quot;, number = 4), data = mytrain_subset2)</p>

<p>#The final step is to apply the model to the test set, which was never used at all for
#anything. These 20 cases were set aside at the outset, read from their own csv file.</p>

<p>predict_FINAL &lt;- predict(modFit, testing, type = &quot;class&quot;)
predict_FINAL</p>

<p>#this prints the prediction for the 20 unknown test cases, which should be around 99% accurate
#(after submitting the 20 cases to the quiz, all 20 were correct)</p>

<p>require(knitr)
require(markdown)
knit(&quot;CourseProjectScript.Rmd&quot;)
markdownToHTML(&#39;CourseProjectScript.md&#39;, &#39;CourseProjectScript.html&#39;, options=c(&quot;use_xhml&quot;))</p>

</body>

</html>
